{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4af5236",
   "metadata": {},
   "source": [
    "# Fake News Classifier model\n",
    "\n",
    "A model built using natural language processing for fake news classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9fbe4d3d",
   "metadata": {},
   "source": [
    "##### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf12dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk \n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d8c26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fake_news_train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa589935",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(\"\", axis=1)\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fca23c16",
   "metadata": {},
   "source": [
    "##### Data Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e14b15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "df['tokenized_text'] = df['text'].apply(tokenize_text)\n",
    "print(df['tokenized_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e06c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "def remove_stopwords(tokens):\n",
    "    filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "    return filtered_tokens\n",
    "\n",
    "df['tokenized_text_stop'] = df['tokenized_text'].apply(remove_stopwords)\n",
    "print(df['tokenized_text_stop'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9f0083e9",
   "metadata": {},
   "source": [
    "##### Data Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8928d91f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_df = df['tokenized_text_stop']\n",
    "y_df = df['label']\n",
    "y_df = y_df.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e065ab89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(tokenizer=lambda doc: doc, lowercase=False)\n",
    "tfidf = tfidf_vectorizer.fit_transform(X_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3bec5c74",
   "metadata": {},
   "source": [
    "#### Model training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002fa916",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf, y_df, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8254cf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a75376",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99d60686",
   "metadata": {},
   "source": [
    "#### Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334f02c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba3e85f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a782fbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The accuracy score is \", accuracy)\n",
    "print(\"The precision score is \", precision)\n",
    "print(\"The recall score is \", recall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
